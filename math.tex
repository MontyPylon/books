\documentclass{article}
\usepackage[utf8]{inputenc}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{float}
\usepackage{setspace}
\usepackage{fixltx2e}
\usepackage{graphicx}
\usepackage{multicol}
\usepackage[normalem]{ulem}
\usepackage{color}
\usepackage{hyperref}
\usepackage{caption}
\usepackage{comment}
\usepackage{multirow}
\usepackage[makeroom]{cancel}
\usepackage{braket}
\usepackage{amsthm}

\newtheorem{theorem}{Theorem}[section]
\numberwithin{theorem}{subsection}
\numberwithin{theorem}{subsubsection}

\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\numberwithin{definition}{subsection}
\numberwithin{definition}{subsubsection}

\title{The Math Book}
\author{Jeremy Cook}
\date{December 2017}

\begin{document}

\maketitle

\tableofcontents
\newpage

\section{Introduction}
This book is intended to store all the useful and beautiful mathematical tools learned throughout my education which I needlessly forget from time to time.

\section{Calculus}

\subsection{Epsilon Delta Proof of Limit} 
The proof that a function has a limit using the epsilon delta proof:
\begin{gather*}
    \lim_{x \rightarrow c} f(x) = L
\end{gather*}

\noindent means that

\begin{gather*}
    \forall \epsilon > 0,\ \exists \delta > 0,\ s.t.\ \forall x,\ 0 < |x - c| < \delta \implies |f(x) - L| < \epsilon.
\end{gather*}

\subsection{Integration by Parts}
The product rule says that 

\begin{gather*}
    \frac{d}{dx}(fg) = \frac{df}{dx}g + f\frac{dg}{dx}
\end{gather*}

\noindent from which it follows that 

\begin{gather*}
    \int_{a}^{b} f \frac{dg}{dx}dx = fg|_{a}^{b} - \int_{a}^{b} \frac{df}{dx}gdx
\end{gather*}

\noindent which can be written more simply as

\begin{gather*}
    \int udv = uv - \int vdu.
\end{gather*}

If the boundary conditions of $uv$ are known, then integration by parts can be very useful, or if you would like to switch which variable is a differential.

\subsection{Differentiation Under the Integral Sign}
Also called the Leibniz integral rule, differentiation under the integral sign states that an integral of the form

\begin{gather*}
    \int_{a(x)}^{b(x)} f(x,t)\,dt,
\end{gather*}

\noindent where $-\infty < a(x),\ b(x) < \infty$, the derivative of this integral is expressible as

\begin{gather*}
    \frac{d}{dx} \left (\int_{a(x)}^{b(x)} f(x,t)\,dt \right ) = \\ f(x,b(x))\cdot \frac{d}{dx} b(x) - f(x,a(x))\cdot \frac{d}{dx} a(x) + \int_{a(x)}^{b(x)}\frac{\partial}{\partial x} f(x,t) \,dt,
\end{gather*}

Notice that if $a(x)$ and $b(x)$ are constants rather than functions of $x$, we have a special case of Leibniz's rule

\begin{gather*}
    \frac{d}{dx} \left(\int_{a}^{b} f(x,t)\,dt \right)= \int_{a}^{b}\frac{\partial}{\partial x} f(x,t) \,dt.
\end{gather*}

\subsection{Series and Sums}
\begin{itemize}
    \item \textbf{Geometric Sum/Series} - A geometric series is a series with a constant ratio between successive terms. For example,
    \begin{equation}
        \frac{1}{2} + \frac{1}{4} + \frac{1}{8} + \frac{1}{16} + ...
    \end{equation}
    The common ratio $r$ is the ratio between an two successive terms. If $r$ is within the range $(-1,1)$, then the terms approach zero and will converge. Outside this range, the sum will converge. The start term $a$ can be used to write the sum as:
    
    \begin{equation}
        a + ar + ar^2 + ar^3 + ... = \sum_{n=0}^{\infty} ar^n
    \end{equation}
    
    If the sum converges, then the sum is equal to:
    
    \begin{equation}
        \sum_{n=0}^{\infty} ar^n = \frac{a}{1 - r},\ \text{for}\ |r| < 1
    \end{equation}
\end{itemize}

\subsection{Exact Differential}
\indent Consider a function $F(x_{1},x_{2})$ that depends on two independent variables $x_{1}$ and $x_{2}$. The differential of $F$ is defined as

\begin{gather*}
    dF = \left ( \frac{\partial F}{\partial x_{1}} \right )_{x_{2}} dx_{1} + \left ( \frac{\partial F}{\partial x_{2}} \right )_{x_{1}} dx_{2} 
\end{gather*}

\noindent where the subscript on the partial derivatives indicates holding that variable fixed(this is the normal definition of a partial derivative, but it is good to be explicit in thermodynamics). If $F$ and its derivatives are continuous and 

\begin{gather*}
    \left [ \frac{\partial}{\partial x_{1}}\left ( \frac{\partial F}{\partial x_{2}} \right )_{x_{1}}\right ]_{x_{2}} = \left [ \frac{\partial}{\partial x_{2}}\left ( \frac{\partial F}{\partial x_{1}} \right )_{x_{2}}\right ]_{x_{1}}
\end{gather*}

\noindent then $F$ is an exact differential. The fact that $dF$ is exact has the following consequences:

\begin{itemize}
    \item[(i)] The value of the integral $F(b) - F(a) = \int_{a}^{b} dF$ is independent of the path taken between $a$ and $b$, and depends only on the endpoints $a$ and $b$.
    \item[(ii)] The integral of $dF$ around a closed path $C$ is zero: $\int_{C} dF = 0.$
    \item[(iii)] If one knows only the quantity $dF$, then the function $F$ can be found to within an additive constant.
\end{itemize}

\indent If $F$ depends on more than two variables, then the statements about can be generalized in a simple way. Let $F = F(x_{1},x_{2},...,x_{n})$, then the differential of $F$ can be written as

\begin{gather*}
    dF = \sum_{i = 1}^{n} \left ( \frac{\partial F}{\partial x_{i}} \right )_{\{x_{j \neq i}\}}dx_{i}.
\end{gather*}

The differential $dF$ is exact if for any pair of variables the following property holds:

\begin{gather*}
    \left [ \frac{\partial}{\partial x_{i}}\left ( \frac{\partial F}{\partial x_{j}} \right )_{\{x_{k \neq j}\}}\right ]_{\{x_{k \neq i}\}} = \left [ \frac{\partial}{\partial x_{j}}\left ( \frac{\partial F}{\partial x_{i}} \right )_{\{x_{k \neq i}\}}\right ]_{\{x_{k \neq j}\}}
\end{gather*}

\begin{comment}
======================================================================================================================================================================================================================================================================================DIFFERENTIAL EQUATIONS=================================================== ====================================================================================================================================================================================================================================
\end{comment}

\section{Differential Equations}

TODO 
\subsection{Separation of Variables}

\begin{comment}
=================================================================================================================================================================================================================================================================== LINEAR ALGEBRA ================================================= ====================================================================================================================================================================================================================================
\end{comment}

\section{Linear Algebra}
 TODO

\begin{comment}
======================================================================================================================================================================================================================================================================================VECTOR CALCULUS=================================================== ====================================================================================================================================================================================================================================
\end{comment}

\section{Vector Calculus}

\subsection{Partial Derivative}
\noindent \textbf{Total derivative vs Partial derivative}\\
A partial derivative  operates under the assumption that you hold all variables fixed while one changes. When computing a total derivative, you allow changes in one variable to affect any of the others.

\begin{comment}
======================================================================================================================================================================================================================================================================================DISCRETE MATH=================================================== ====================================================================================================================================================================================================================================
\end{comment}

\section{Discrete Math}

\subsection{Propositional Logic}

\begin{flushleft}
\textbf{Propositional}
\end{flushleft}
A statement that is either true or false. Example: Austin in the capital of Texas.


\begin{flushleft}
\textbf{Logical Connective}
\end{flushleft}
A logical operator that takes one or two propositional variables and applies an operation on them to produce a single true or false value. The connectives are:


\begin{table}[H]
  \begin{center}
    \begin{tabular}{l|c|l} % <-- Alignments: 1st column left, 2nd middle and 3rd right, with vertical lines in between
      \textbf{Connective} & \textbf{Symbol} & \textbf{English}\\
      \hline
      Negation & $\neg$ & not\\
      Conjunction & $\wedge$ & and\\
      Disjunction & $\vee$ & or\\
      Implication & $\implies$ & implies\\
      Biconditional & $\iff$ & iff\\
      Exclusive Or & $\oplus$ & XOR\\
      Equality & $\equiv$ & equivalent\\
      Not And & $\uparrow$ & NAND\\
    \end{tabular}
  \end{center}
\end{table}

\begin{flushleft}
\textbf{Truth Tables}
\end{flushleft}

\begin{table}[H]
    \begin{minipage}{.25\linewidth}
      \caption*{\textbf{AND}}
      \centering
        \begin{tabular}{c|c|c}
             p & q & p $\vee$ q\\
             \hline
             T & T & T \\
             T & F & F \\
             F & T & F \\
             F & F & F \\
        \end{tabular}
    \end{minipage}%
    \begin{minipage}{.25\linewidth}
      \centering
        \caption*{\textbf{OR}}
        \begin{tabular}{c|c|c}
             p & q & p $\vee$ q\\
             \hline
             T & T & T \\
             T & F & T \\
             F & T & T \\
             F & F & F \\
        \end{tabular}
    \end{minipage}%
    \begin{minipage}{.25\linewidth}
      \centering
        \caption*{\textbf{XOR}}
        \begin{tabular}{c|c|c}
             p & q & p $\vee$ q\\
             \hline
             T & T & F \\
             T & F & T \\
             F & T & T \\
             F & F & F \\
        \end{tabular}
    \end{minipage}%
    \begin{minipage}{.25\linewidth}
      \centering
        \caption*{\textbf{NAND}}
        \begin{tabular}{c|c|c}
             p & q & p $\vee$ q\\
             \hline
             T & T & F \\
             T & F & T \\
             F & T & T \\
             F & F & T \\
        \end{tabular}
    \end{minipage}%
\end{table}


\section{Set Theory}
A set is an unordered collection of distinct objects. Some important sets include:

\begin{table}[H]
    \centering
    \begin{tabular}{l l l}
         $\emptyset : $ empty set & $\mathbb{Z}:$ integers & $\mathbb{Z}^{+}:$ positive integers \\
         $\mathbb{Z}^{-}:$ negative integers & $\mathbb{N}:$ natural numbers & $\mathbb{R}:$ real numbers \\
         $\mathbb{Q}:$ rational numbers & $\mathbb{C}:$ complex numbers & $\Omega:$ universal set
    \end{tabular}
    \label{tab:my_label}
\end{table}

\noindent{\textbf{Cardinality}} \\
\indent $|S| = $ number of elements in the set \\

\noindent{\textbf{Universal Set}} \\
\indent Equivalent to universe of discourse. All possible elements are in this set.\\

\noindent{\textbf{Singleton Set}} \\
\indent Set with cardinality of 1, meaning a single element in the set.\\

\noindent \textbf{Subset} \\
\indent A set A is a subset of a set B, or equivalently B is a superset of A, if A is ``contained" inside B, that is, all elements of A are also elements of B. A and B may coincide.
\begin{center}
    $A \subseteq B \equiv \forall x.(x \in A \rightarrow x \in B)$\\    
\end{center}

\noindent \textbf{Proper (Strict) Subset} \\
\indent A subset is a proper subset if the subset does not contain all of the elements in its superset.
\begin{equation*}
    A \subset B \equiv \forall x.(x \in A \rightarrow x \in B) \land \exists x.(x \in B \land x \notin A)   
\end{equation*}

\noindent \textbf{Set Equality}
\indent Two sets are equal if and only if they have the same elements. Equivalently, if the two sets are subsets of each other, then they are equal.
\begin{equation*}
    A = B \equiv (A \subseteq B) \land (B \subseteq A) \equiv \forall x.(x \in A \iff x \in B)
\end{equation*}

\noindent \textbf{Power Set}

$\mathcal{P}(S)$ is the set of all subsets of S. For example, the powerset of the set $S = \{a,b,c\}$ is:
\begin{equation*}
    \mathcal{P}(S) = \{\emptyset, \{a\}, \{b\}, \{c\}, \{a,b\}, \{a,c\}, \{b,c\}, \{a,b,c\}\}
\end{equation*}
\noindent If $|S| = n$, then $|\mathcal{P}(S)| = 2^{n}$. \\

\noindent \textbf{Cartesian Product} \\
\indent A Cartesian product is a mathematical operation that returns a set of tuples from multiple sets. That is, for sets A and B, the Cartesian product A $\times$ B is the set of all ordered pairs (a, b) where $a \in A$ and $b \in B$. Products can be specified as following:
\begin{equation*}
    A\times B = \{\,(a,b)\mid a\in A \ \land \ b\in B\,\}
\end{equation*}

\noindent In general, $A \times B \neq B \times A$. This is because the tuples are ordered, unlike sets. For example, take the set $A = \{a,b,c\}$ and $B = \{1,2,3\}$.

\begin{gather*}
    A \times B = \{(a,1),(a,2),(a,3),(b,1),(b,2),(b,3)\} \\
    B \times A = \{(1,a),(2,a),(3,a),(1,b),(2,b),(3,b)\}
\end{gather*}

\noindent Also, $|A \times B| = |A||B|$. \\

\noindent \textbf{Union} \\
\indent $A \cup B = \{x\ |\ (x \in A) \lor (x \in B)\}$ \\

\noindent \textbf{Intersection} \\
\indent $A \cap B = \{x\ |\ (x \in A) \land (x \in B)\}$ \\

\noindent \textbf{Difference} \\
\indent $A \setminus B = \{x\ |\ (x \in A) \land (x \notin B)\}$ \\

\noindent \textbf{Complement} \\
\indent $A^{C} = \overline{A} = \{x\ |\ x \notin A\}$ \\

\subsection{Algebra of Sets}
\begin{itemize}
    \item The Idempotent Laws 
    \begin{gather*}
        X \cup X = X \quad \text{and} \quad X \cap X = X
    \end{gather*}
    \item The Commutative Laws
    \begin{gather*}
        X \cup Y = Y \cup X \quad \text{and} \quad X \cap Y = Y \cap X
    \end{gather*}
    \item The Associative Laws
    \begin{gather*}
        X \cup (Y \cup Z) = (X \cup Y) \cup Z \quad \text{and} \quad X \cap (Y \cap Z) = (X \cap Y) \cap Z
    \end{gather*}
    \item The Distributive Laws
    \begin{gather*}
        X \cup (Y \cap Z) = (X \cup Y) \cap (X \cup Z) \quad \text{and} \quad X \cap (Y \cup Z) = (X \cap Y) \cup (X \cap Z)
    \end{gather*}
    \item{The Identity Laws}
    \begin{gather*}
        X \cup \emptyset = X \quad X \cap \Omega = X \quad X \cap \emptyset = \emptyset \quad X \cup \Omega = \Omega
    \end{gather*}
    \item{The Complement Laws}
    \begin{gather*}
        X \cup X^{c} = \Omega \quad X \cap X^{c} = \emptyset \quad (X^{c})^{c} = X \quad \Omega^{c} = \emptyset \quad \emptyset^{c} = \Omega
    \end{gather*}
    \item{The De Morgan's Laws}
    \begin{itemize}
        \item $X\ \backslash \ (Y \cup Z) = (X\ \backslash \ Y) \cap (X\ \backslash\  Z)$
        \item $X\ \backslash \ (Y \cap Z) = (X\ \backslash\ Y) \cup (X\ \backslash\ Z)$
        \item $(X \cup Y)^{c} = X^{c} \cap Y^{c}$
        \item $(X \cap Y)^{c} = X^{c} \cup Y^{c}$
        \item $(\cup_{k=1}^{\infty}X_{k})^{c} = \cap_{k=1}^{\infty}X_{k}^{c}$
        \item $(\cap_{k=1}^{\infty}X_{k})^{c} = \cup_{k=1}^{\infty}X_{k}^{c}$
    \end{itemize}
    
\end{itemize}

\noindent \textbf{Russell's Paradox} \\
\indent Russell's paradox revealed a great but subtle flaw in naive set theory. Consider Russell's set, a set of all sets which don't contain themselves:
\begin{equation*}
    R = \{S\ |\ S \notin S\}
\end{equation*}
\noindent Then if $R \in R$ this yeilds a contradiction, because any element of R cannot contain itself. But if $R \notin R$, this also yields a contradiction because if $R$ doesn't contain itself, it should be an element of $R$ by the definition of $R$.

\begin{comment}
======================================================================================================================================================================================================================================================================================REAL ANALYSIS================================================ ====================================================================================================================================================================================================================================
\end{comment}

\section{Real Analysis}

\subsection{Ordering Relations}
\noindent \textbf{Binary Relation} \\
\indent A binary relation between set $X$ and set $Y$ is a subset of $X \times Y$. When $X = Y$ we say the binary relation is on X.
\\
\indent If $x \in X$ and $y \in Y$ are related by binary relation between $X$ and $Y$, we write $xRy$. If $x$ and $y$ are not related by relation $R$, we write $x\cancel{R}y$. \\
\indent A function $f: X \rightarrow Y$ is a binary relation such that if $xRy$ then $x\cancel{R}\Tilde{y}, \forall \Tilde{y}( \neq y) \in Y$.
\\

\noindent \textbf{Ordering Relation} An ordering on a set $X$ is a binary relation, denoted by $\leq$, that satisfies the following properties:

\begin{itemize}
    \item \textbf{Reflexivity}: $x \leq x \ \forall x \in X$.
    \item \textbf{Anti-symmetry}: $x \leq y$ and $y \leq x \implies x = y$.
    \item \textbf{Transitive}: $x \leq y$ and $y \leq z \implies x \leq z$.
\end{itemize}

\noindent $\left \{ X, \leq \right \}$ is called an ordering space and $X$ an order set (sometimes called a partially ordered set. \\

\noindent \textbf{Totally Ordered Set}\\
\indent A totally ordered set is a set in which any two elements can be compared, which leads naturally to the concepts of a maximal and minimal elements. \\


\noindent \textbf{Minimal and Maximal Element}\\
\indent Minimal element: $\underline{m} \in X\ s.t.\ \underline{m} \leq x, \forall x \in X$.\\
\indent Maximal element: $\overline{m} \in X s.t.\ x \leq \overline{m}, \forall x \in X$.
\\

\noindent \textbf{Infimum and Suprimum}\\
\indent Let $(X, \leq)$ be an ordering space, and $\Tilde{X}$ be a non-empty subset of $X$. \\
\indent The infimum is the greatest lower bound of a set $\Tilde{X}$. More formally, a lower bound is a number $\underline{x} \in X$ such that $\underline{x} \leq x\  \forall x \in \Tilde{X}$. If $\underline{x} \leq \underline{x_{0}}$ for any lower bound $\underline{x}$, we call $\underline{x_{0}}$ the infimum. \\
\indent The supremum is the smallest upper bound of a set $\Tilde{X}$. Formally, an upper bound is a number $\overline{x} \in X$ such that $x \leq \overline{x}\ \forall x \in \Tilde{X}$. If $\overline{x_{0}} \leq \overline{x}$ for any upper bound $\overline{x}$, we call $\overline{x_0}$ the supremum.


\subsection{Equivalence Relations}
An equivalence relation on $X$, denoted by $~$, is a binary relation on $X$ such that

\begin{itemize}
    \item \textbf{Reflexivity}: $x \sim x\ \forall x \in X$.
    \item \textbf{Symmetry}: $x \sim y \Leftrightarrow y \sim x$.
    \item \textbf{Transitivity}: $x \sim y$ and $y \sim z \implies x \sim z$
\end{itemize}

\noindent The equivalence class of an element $x$ with the relation $\sim$, denoted by $[x]_{\sim}$, is the set $[x]_{\sim} = \{y|y \in X\ \text{and}\ y \sim x\}$. The quotient set of $X$ with respect to equivalence relation $\sim$ is the set of all equivalence classes,

\begin{gather*}
    X/ \sim = \{[y]_{\sim}|y \in X\}.
\end{gather*}

\noindent For example, let $X = \{x,y,z\}$. We can then define the equivalence relation $~$ on $X$ as

\begin{gather*}
    ~= \{(x,x),(y,y),(z,z),(x,y),(y,x)\}.
\end{gather*}

\noindent Then $[x]_{\sim} = [y]_{\sim} = \{x,y\}$ is an equivalence class and $[z]_{\sim} = \{z\}$ is another equivalence class.
\\

\noindent \textbf{Properties of Equivalence Classes}
\begin{itemize}
    \item (i) $\forall x \in X, x \in [x]_{\sim}$.
    \item (ii) If $y \in [x]_{\sim} \implies x \in [y]_{\sim}$ and $[x]_{\sim} = [y]_{\sim}$.
    \item (iii) $\forall x, y \in X,$ either $[x]_{\sim} = [y]_{\sim}$ or $[x]_{\sim} \cap [y]_{\sim} = \emptyset$.\\
\end{itemize}

\noindent \textbf{Partitions}\\
\indent Let $X$ be a set and $A$ an index set. Let $\{X_{\alpha}\}_{\alpha \in A}$ be a family of nonempty (i.e. $X_{\alpha} \neq \emptyset\ \forall \alpha \in A$) disjoint (i.e. $X_{\alpha} \cap Y_{\beta} = \emptyset\ \forall \alpha \neq \beta \in A$) subsets of $X$. This is called a partition of $X$ if $X = \cup_{\alpha \in A}X_{\alpha}$.\\
\indent Every equivalence relation $\sim$ introduces a partition of $X$, and every partition of $X$ introduces an equivalence relation on $X$.

\subsection{Functions}
\noindent \textbf{Injectivity, Surjectivity, Bijectivity} \\
\indent A function $f(x) : X \rightarrow Y$ can be:
\begin{itemize}
    \item Injective (One-to-one): $x_{1} \neq x_{2} \in X \implies f(x_{1}) \neq f(x_{2}) \in Y$.
    \item Surjective (Onto): $Range(f) = Y$ or $\forall y \in Y,\ \exists x \in X\ s.t.\ f(x) = y$.
    \item Bijective: $f(x)$ is both injective and surjective.\\
\end{itemize}

\noindent \textbf{Characteristic Function} \\
\indent The characteristic function of a set $X$ is defined as
\begin{gather*}
    \chi_{X}(x) =  \begin{cases} 
                      1, & x \in X \\
                      0, & x \in X^{c}
                   \end{cases}
\end{gather*}

\noindent \textbf{Extension and Restriction} \\
\indent Let $f : E \rightarrow F$ and $g : X \rightarrow Y$. If $E \subset X$ and $g(x) = f(x),\ \forall x \in E$, we call $g$ the extension of $f$ to $X$ and $f$ the restriction of $g$ to $E$, denoted by $f = g|_{E}$. \\

\noindent \textbf{Product, Summation, and Composition} \\
\indent Let $f : X \rightarrow Y,\ g : X \rightarrow Y,$ and $h : Y \rightarrow Z$.
\begin{itemize}
    \item Product: $fg(x) = f(x)g(x)$. The domain is $Dom(fg) = Dom(f) \cap Dom(g)$.
    \item Summation: $(f + g)(x) = f(x) + g(x)$. The domain is $Dom(f+g) = Dom(f) \cap Dom(g)$.
    \item Composition: $f \circ g(x) = g(f(x))$. The domain is $Dom(f \circ g) = \{x|x\in Dom(f), f(x) \in Dom(g)\}$.\\
\end{itemize}

\noindent \textbf{Inverse Function} \\
\indent Let $f:X \rightarrow Y$ be a function. We say $f$ is invertible if there exists a function, denoted by $f^{-1}:Ran(f) \rightarrow X$ with the property:

\begin{gather*}
    f(x) = y \iff f^{-1}(y) = x,\ \forall y \in Ran(f)
\end{gather*}

\noindent or equivalently,

\begin{gather*}
    f \circ f^{-1}(y) = y,\ \forall y \in Ran(f)\ \text{and}\ f^{-1} \circ f(x) = x,\ \forall x \in Dom(f).
\end{gather*}

\indent In general, $f^{-1}(x) \neq (f(x))^{-1} = \frac{1}{f(x)}$. The notation $f^{1}$ can also denote the pre-image of a set. To avoid confusion, I will use square brackets to denote pre-image, and round brackets to denote the inverse function. For exmaple, the pre-image of the set $X$ is $f^{-1}[X]$, while the inverse function of $f$ will be $f^{-1}(x)$ at $x$. \\

\noindent \textbf{Invertibility of Injective Functions} \\
\indent If $f:X \rightarrow Y$ be a function that is injective, then $f$ is also invertible. \textit{Proof}:\\
$f$ is injective, so $\forall y \in Ran(f), \exists!x \in Dom(f)\ s.t.\ f(x) = y$. Define $f^{-1}(y) = x$ with $x$ s.t. $f(x) = y$. Then $f^{-1}: Ran(f) \rightarrow X$ is a function and satisfies the requirements of an inverse function for $f$. \\

\noindent \textbf{Uniqueness of Inverse Functions} \\
\indent If $f: X \rightarrow Y$ is a function that is invertible, then its inverse function $f^{-1}$ is unique.

\subsection{Basic Topology}
Topology is concerned with the properites of space that are preserved under continuous deformations, such as stretching, crumpling and bending, but not tearing or gluing. This can be studied by considering a collection of subsets, called open sets, that satisfy certain properties, turning the given set into what is known as a topological space. \\

\noindent \textbf{Cardinality} \\
\indent The cardinality of a set is the number of distinct elements in a set. The cardinality of the empty set is define to be 0 $(|\emptyset| = 0)$. If we let $X$ and $Y$ be nonempty sets, then the cardinality of the sets, $|X|$ and $|Y|$, are numbers that satisfy

\begin{gather*}
    |X| \leq |Y|, |X| = |Y|, |X| \geq |Y|
\end{gather*}

\noindent if there exists $f: X \rightarrow Y$, with $Dom(f) = X$ that is injective, bijective, or surjective respectively. We replace $\leq$ with $<$ when the function is injective but not bijective from $X$ to $Y$, and we replace $\geq$ with $>$ when the function is surjective but not bijective from $X$ to $Y$. \\

\noindent \textbf{Finite, Countable, and Uncountable Sets} \\
\indent For any positive integer $n$, let $J_{n}$ be the set whose elements are the integers $1,2,...,n$. Let $J$ be the set consisting of all positive integers. If there exists a 1-1 mapping of $A$ onto $B$, we say that $A$ and $B$ can be put in a 1-1 correspondence, or that $A$ and $B$ have the same cardinal number, or that $A$ and $B$ are equivalent, and we write $A \sim B$. Then for any set $A$ we say
\begin{itemize}
    \item $A$ is \textbf{finite} if $A \sim J_{n}$ for some $n$.
    \item $A$ is \textbf{infinite} if $A$ is not finite.
    \item $A$ is \textbf{countable} if $A \sim J$.
    \item $A$ is \textbf{uncountable} if $A$ is neither finite nor countable.
    \item $A$ is \textbf{at most countable} if $A$ is finite or countable.
\end{itemize}


\noindent \textbf{Theorems} \\
\indent Infinite subsets of countable sets are countable. \\
\indent Cartesian products of countable sets are countable. If $S$ and $T$ are both countable, then $S \times T$ is countable.\\
\indent Cantor's Theorem - There is no surjective function from $X$ and $\mathcal{P}(X)$ with domain $X$, i.e. $|X| < |\mathcal{P}(X)|$.  \\
\indent Take $X = \mathbb{N}$. Cantor's theorem then says that the collection of all subsets of $\mathbb{N}$ is uncountable. 

\subsection{Metric Space}

\noindent \textbf{Metric Space Definition} \\
\indent Let $X$ be a set and $\rho: X \times X \rightarrow [0,\infty)$ a function. $\rho$ is called a metric if
\begin{itemize}
    \item (i) (Non-negativity) $\rho(x,y) \geq 0,\ \forall x,y \in X.\ \rho(x,y) = 0$ iff $x = y$.
    \item (ii) (Symmetry) $\rho(x,y) = \rho(y,x)\ \forall x,y \in X$. 
    \item (iii) (Triangle Inequality) $\rho(x,y) \leq \rho(x,z) + \rho(z,y)\ \forall x,y,z \in X$.
\end{itemize}
We call $(X,\rho)$ a metric space. The value $\rho(x,y)$ is called the distance between element $x$ and element $y$ in metric $\rho$.
\\

\noindent \textbf{Equivalence of Metrics} \\
\indent Two metrics, $\rho$ and $\sigma$, on a set $X$ are said to be equivalent if $\forall x \in X,\ \forall \epsilon > 0,\ \exists \delta(\epsilon, x)$ s.t. $\forall y \in X$,

\begin{gather*}
    \rho(x,y) \leq \delta(\epsilon, x) \implies \sigma(x,y) \leq \epsilon,
\end{gather*}
\noindent and
\begin{gather*}
    \sigma(x,y) \leq \delta(\epsilon, x) \implies \rho(x,y) \leq \epsilon.
\end{gather*}
\indent Two metrics $\rho$ and $\sigma$, on a set $X$ are said to be uniformly equivalent if there exists positive constants $c_{1}$ and $c_{2}$ such that
\begin{gather*}
    c_{1}\rho(x,y) \leq \sigma(x,y) \leq c_{2}\rho(x,y),\ \forall x,y\in X.
\end{gather*}

\subsection{Open and Closed Sets}

\noindent \textbf{Open and Closed Balls} \\
\indent Let $(X,\rho)$ be a metric space. The open and closed balls centered at $x$ with radius $r$ are respectively the sets

\begin{gather*}
    B_{r} (x) \equiv \{y \in X | \rho (x,y) < r\} \quad \text{and} \quad \overline{B}_{r} (x) \equiv \{y \in X | \rho (x,y) \leq r\}.
\end{gather*}

\noindent The open ball $B_{r}$ is usually called the neighborhood of center $x$ with radius $r$.
\\

\noindent \textbf{Open and Closed Sets} \\
\indent Let $(X, \rho)$ be a metric space. A set $S \subseteq X$ is open in $X$ if, $\forall x \in S,\ \exists \epsilon > 0\ s.t.\ B_{\epsilon} \subseteq S$. A set $S$ is closed if its complement $S^{c}$ (relative to $X$) is open. It then follows that the set $B_{r}(x)$ is open and the set $\overline{B}_{r}(x)$ is closed.
\\

\noindent \textbf{Axoim of Open Sets} \\
\indent Let $(X, \rho)$ be a metric space. Then the sets $\emptyset$ and $X$ are both open and closed. Sets that are both open and closed are often called clopen sets.
\\

\noindent \textbf{Union and Intersection of Open Sets} \\
\indent Let $(X, \rho)$ be a metric space and $\{O_{k}\}_{k=1}^{\infty}$ be a countable collection of open sets in $X$. Then

\begin{itemize}
    \item[(i)] $\cap_{k=1}^{N} O_{k}$ is open for any finite $N < \infty$.
    \item[(ii)] $\cup_{k=1}^{\infty} O_{k}$ is open.
\end{itemize}

\noindent \textbf{Union and Intersection of Closed Sets} \\
\indent Let $(X, \rho)$ be a metric space and $\{\Tilde{O}_{k}\}_{k=1}^{\infty}$ be a countable collection of closed sets in $X$. Then

\begin{itemize}
    \item[(i)] $\cup_{k=1}^{N} \Tilde{O}_{k}$ is closed for any finite $N < \infty$.
    \item[(ii)] $\cup_{k=1}^{\infty} \Tilde{O}_{k}$ is closed.
\end{itemize}

\noindent \textbf{Limit Point, Point of Closure, and Isolated Point} \\
\indent Let $(X,\rho)$ be a metric space, and $S \subseteq X$ a subset. A point $x \in X$ is called a limit point of $S$ if $\forall \epsilon > 0,\ \exists y \neq x \in B_{\epsilon} (x)\ s.t.\ y \in S$. We denote $S'$ as the set of limit points of $S$. \par
A point $x \in X$ is called a point of closure of $S$ if $\forall \epsilon > 0,\ \exists y \in B_{\epsilon}(x)\ s.t.\ y \in S$. We denote $\overline{S}$ as the closure of $S$, i.e. the set of points of closure of $S$. A point of closure of $S$ that is not a limit point is called an isolated point. By definition every limit point is a point of closure but not vice versa.

\begin{theorem}
    Let $(X,\rho)$ be a metric space and $S \subseteq X$ a subset. Then $S$ is closed if and only if $S' \subseteq S$.
\end{theorem}

\subsection{Sequences} 
\noindent \textbf{Convergence}\\
\indent Let $(X,\rho)$ be a metric space and $\{x_{n}\}$ a sequence in $X$. We say that $\{x_{n}\}$ converges (in metric $\rho$) to $x \in X$ if 

\begin{gather*}
    \forall \epsilon > 0,\ \exists N(\epsilon) \in \mathbb{N},\ s.t.\ \rho(x_{n},x) \leq \epsilon,\ \forall n \geq N(\epsilon).
\end{gather*}

\noindent When $\{x_{n}\}$ converges to $x$, we write $x_{n} \rightarrow x$ and call $x$ the limit of the sequence in metric $\rho$.
\\

\noindent \textbf{Equivalent Definition of Convergence} \\
\indent Let $(X,\rho)$ be a metric space and $\{x_{n}\}$ a sequence in $X$. Then $x_{n} \rightarrow x$ if and only if $\rho(x_{n},x) \rightarrow 0$ as $n\rightarrow \infty$. 

\begin{theorem}
    Let $\rho$ and $\sigma$ be two equivalent metrix defined on $X$ and $\{x_{n}\}$ be a sequence in $X$. Then $x_{n} \rightarrow x$ in metric $\rho$ iff $x_{n} \rightarrow x$ in $\sigma$.
\end{theorem}

\begin{theorem}[Uniqueness of Limit]
    Let $(X,\rho)$ be a metric space and $\{x_{n}\}$ be a sequence in $X$. Then $x_{n} \rightarrow x$ and $x_{n} \rightarrow y$ then $x = y$.
\end{theorem}

\begin{theorem}
    Let $x_{n} \rightarrow x$ and $y_{n} \rightarrow y$ in metric space $(X,\rho)$. Then $\rho(x_{n},y_{n}) \rightarrow \rho(x,y)$.
\end{theorem}

\begin{theorem}[Sequential Characterization of Limit Point]
    Let $(X, \rho)$ be a metric space and $S \subseteq X$ a subset. A point $x \in X$ is a limit point of $S$ if and only if there exists a non-constant sequence of points $\{x_{n}\} \subseteq S$ s.t. $x_{n} \rightarrow x$ in metric $\rho$.
\end{theorem}

\begin{theorem}[Sequential Characterization of Closedness]
    Let $(X,\rho)$ be a metric space and $S \subseteq X$ a subset. Then $S$ is closed if and only if the limit of every convergent sequence in $S$ belongs to $S$.
\end{theorem}

When the limit of every convergent sequence in $S$ belongs to $S$ it is often said that $S$ is \textit{sequentially closed}. The above theorem says that $S$ is closed if and only if it is sequentially closed.
\\


\subsubsection{Cauchy Sequence} 

\begin{definition}[Cauchy Sequence]
    A sequence $\{x_{n}\}$ in a metric space $(X,\rho)$ is said to be a \textit{Cauchy sequence} if $\forall \epsilon > 0,\ \exists N \in \mathbb{N}$ s.t. $\rho(x_{n},x_{m}) < \epsilon$ for any pair $(n,m)$ if $n \geq N$ and $m \geq N$.
\end{definition}

\begin{definition}[Complete]
    A metric space in which every Cauchy sequence converges is said to be \textit{complete}.
\end{definition}

\begin{definition}[Monotonicity]
    A sequence $\{s_{n}\}$ of real numbers is said to be
    \begin{itemize}
        \item[(i)] \textit{monotonically increasing} if $s_{n} \leq s_{n+1}\ (n = 1,2,3,...)$;
        \item[(ii)] \textit{monotonically decreasing} if $s_{n} \geq s_{n+1}\ (n = 1,2,3,...)$;
    \end{itemize}
\end{definition}


\begin{comment}
======================================================================================================================================================================================================================================================================================COMPLEX ANALYSIS================================================ ====================================================================================================================================================================================================================================
\end{comment}

\section{Complex Analysis}

\subsection{Identities}

\begin{gather*}
    i = \sqrt{-1} \quad \quad \quad z = x + iy \\
    \left | \frac{a}{b}\right | = \frac{|a|}{|b|} \quad \quad \quad |ab| = |a||b|
\end{gather*}

\subsection{Triangular Inequality}
\begin{gather*}
    |a + b| \leq |a| + |b|
\end{gather*}

\subsection{Cauchy-Goursat Theorem}

If two different paths connect the same two points in the complex plane, and a function is holomorphic (or analytic) everywhere between the two paths, then the two path integrals of the function will be the same.


\begin{comment}
======================================================================================================================================================================================================================================================================================PROBABILITY THEORY================================================ ====================================================================================================================================================================================================================================
\end{comment}

\section{Probability Theory}

\subsection{Multiplication and Addition Principle}
\noindent \textbf{Multiplication Principle} \\
\indent If an event can be broken down into two stages where sub-event $A$ comes first and has $N(A)$ possibilities, and then sub-event $B$ occurs with $N(B)$ possibilities, then there are a total of $N(A) \cdot N(B)$ number of events that can occur. \\

\noindent \textbf{Addition Principle} \\
\indent If an event can be broken down into independent events that can be executed in any order, then we can add the total number of outcomes together. For example if event $A$ and event $B$ occur independently of each other, and there are $N(A)$ possible outcomes for event $A$, and $N(B)$ possible outcomes for event $B$, then there are a total of $N(A) + N(B)$ total number of outcomes.

\subsection{Combinations vs Permutations}
A combination is how many ways can you pick a number of objects from a group of objects, permutations are how many ways you can arrange a number of items.

\begin{table}[H]
    \centering
    \begin{tabular}{c | c | c}
        Order Matters & \multicolumn{2}{c}{How many ways to pick r objects from...}\\
        \hline
         & n objects & n types of objects \\
         \hline
        \multirow{2}{*}{Yes} & Permutation & Permutation w/ repetition \\
        & $P(n,r) = \frac{n!}{(n-r)!}$ & $P^{*}(n,r) = n^{r}$ \\
        \hline
        \multirow{2}{*}{No} & Combination & Combination w/ repetition \\
        & $C(n,r) = \frac{n!}{r!(n-r)!}$ & $C^{*}(n,r) = \frac{(n+r-1)!}{r!(n-1)!}$ \\
    \end{tabular}
    \label{tab:my_label}
\end{table}

\noindent For permutations with $n$ types of objects which $k_{1}$ objects of type $1$, $k_{2}$ objects of type $2$, etc. 
\begin{gather*}
    \frac{k!}{k_{1}!k_{2}!k_{3}!...k_{n}!}
\end{gather*}

\subsection{Binomial and Multinomial Theorem}

\noindent \textbf{Binomial Theorem} \\
\indent The binomial theorem describes the algebraic expansion of powers of any binomial.
\begin{equation*}
    (x+y)^{n} = \sum_{k=0}^{n} {n\choose k} x^{k}y^{n-k}
\end{equation*}
\\

\noindent \textbf{Corollaries from the Binomial Theorem} \\
\begin{gather*}
    \sum_{k=0}^{n} {n\choose k} = 2^{n} \\
    \sum_{k=0}^{n} (-1)^{k} {n\choose k} = 0
\end{gather*}

\noindent \textbf{Pascal's Identity} \\
\begin{gather*}
    {n+1 \choose k} = {n \choose k-1} + {n\choose k}
\end{gather*}


\subsection{General Rules}

\noindent \textbf{Independence} \\
\indent Let A and B be events with non-zero probabilities. A and B are independent if any (and hence all) of the following hold:
\begin{enumerate}
    \item $P(A|B) = P(A)$, or
    \item $P(B|A) = P(B)$, or
    \item $P(A \cap B) = P(A)P(B)$.
\end{enumerate}

\noindent \textbf{Identities} \\
\indent For two variables,

\begin{enumerate}
    \item $P(A \cap B) = P(A) + P(B) - P(A \cup B)$
    \item $P(A \cup B) = P(A) + P(B) - P(A \cap B)$
\end{enumerate}

and for three,

\begin{enumerate}
    \item $P(A \cup B \cup C) = P(A) + P(B) + P(C) - P(A \cap B) - P(A \cap C) - P(B \cap C) + P(A \cap B \cap C)$
    \item $P(A \cap B \cap C) = P(A) + P(B) + P(C) - P(A \cap B) - P(A \cap C) - P(B \cap C) + P(A \cup B \cup C)$
\end{enumerate}

\noindent \textbf{Conditional Probability} \\
\indent The probability of event A given that event $B$ has already occurred is written as $P(A|B)$.

\begin{gather*}
    P(A|B) = \frac{P(A \cap B)}{P(B)}
\end{gather*}

\noindent If two events A and B are mutually exclusive, then $P(A \cap B) = \emptyset$ and $P(A \cup B) = P(A) + P(B)$.\\

\noindent \textbf{Bayes Theorem} \\
\indent Suppose that the sample space S is partitioned into $n$ disjoint subsets $B_{1},B_{2},...,B_{n}$ with nonempty probabilities, $P_{r}(B_{i}) > 0\ \forall i \in {1,2,...,n}$, and $B_{i} \cap B_{j} = \emptyset\ \forall i \neq j$. Then for an event A,

\begin{gather*}
    P_{r}(B_{j} | A) = \frac{P_{r}(B_{j} \cap A)}{P_{r}(A)} = \frac{P_{r}(B_{j}) \cdot P_{r}(A | B_{j})}{\sum_{i = 1}^{n} P_{r}(B_{i}) \cdot P_{r}(A | B_{i})}
\end{gather*}


\subsection{Discrete Stochastic Variables}

We say $X$ is a discrete stochastic (random) variable if $X$ is a numerically valued function whose domain is the sample space of a probability experiment with a finite or countably infinite number of outcomes. \par
Every random variable has a probability distribution associated with it, and there exists a one-to-one mapping between the two. \\

\noindent \textbf{Expectation Value} \\
\indent If $X$ is a discrete random variable with probability function $p(x_{i})$, then the expectation value (mean) of the random variable $X$ is given by,

\begin{gather*}
    E[X] = \sum_{i}^{\infty} x_{i}p(x_{i})
\end{gather*}

\noindent and for an arbitrary function $g(X)$, we call $Y = g(x)$ a transformation of $X$ such that

\begin{gather*}
    E[Y] = E[g(X)] = \sum_{i}^{\infty} g(x_{i})p(x_{i}).
\end{gather*}

The expectation value of a linear transform is also linear. For example, take the transformation $Y = aX + b$, the expectation value of $Y$ is then

\begin{gather*}
   E[Y] = E[aX + b] = a\cdot E[X] + b. 
\end{gather*}

\noindent \textbf{Median}\\
\indent If $X = \{x_{1},x_{2},...,x_{n}\}$ is a collection of $n$ \textit{sorted} data points then the median of the data is

\begin{gather*}
    M(X) =  \begin{cases} 
                      x_{\cfrac{n+1}{2}}\ , & $n$ \text{ is odd}\\\\
                      \cfrac{x_{\cfrac{n}{2}} + x_{\cfrac{n}{2} + 1}}{2}\ , & $n$ \text{ is even}
                   \end{cases}
\end{gather*}

\noindent \textbf{Midrange} \\
\indent If $X = \{x_{1},x_{2},...,x_{n}\}$ is a collection of $n$ \textit{sorted} data points then the midrange of the data is

\begin{gather*}
    \frac{x_{1} + x_{n}}{2}.
\end{gather*}

\noindent \textbf{Mode} \\
\indent If $X = \{x_{1},x_{2},...,x_{n}\}$ is a collection of $n$ \textit{sorted} data points then the mode of the data is the value $x_{i}$ that occurs most frequently. If two values occur the same number of times (and more often than any other value), we say the data is bi-modal. Otherwise, the mode does not exist.
\\

\noindent \textbf{Percentiles} \\
\indent If $X = \{x_{1},x_{2},...,x_{n}\}$ is a collection of $n$ \textit{sorted} data points then $x_{i}$ corresponds to the

\begin{gather*}
    \left ( 100 \cdot \frac{i}{n+1}\right )^{th} \text{ percentile}.
\end{gather*}

\indent Linear interpolation can be used to find the value of a fractional data point.\\

\noindent \textbf{Variance} \\
\begin{gather*}
    Var[X] = \sigma_{X}^{2} = \sum_{x_{i}} (x_{i} - \mu_{x})^{2} \cdot p(x_{1}).    
\end{gather*}

or

\begin{gather*}
    Var[X] = E[X^2] - (E[X])^{2} = \sum_{x_{1}} x_{i}^{2} p(x_{i}) - \left ( \sum_{x_{i}} x_{i} p(x_{i})\right )^{2} \\
    = \sum_{x_{i}} x_{i}^{2} p(x_{i}) - \mu_{x}^{2}.
\end{gather*}

\noindent \textbf{Mean and Variance of a Linear Transformation} \\
\indent Let $X$ be a discrete random variable and let $Y = a\cdot X + b$, where $a,b \in \mathbb{R}$. Then,
\begin{itemize}
    \item[1.] \quad $E[Y] = E[a\cdot X + b] = a\cdot E[x] + b$.
    \item[2.] \quad $Var[Y] = Var[a\cdot X + b] = a^2 \cdot Var[X]$. 
\end{itemize}

\noindent \textbf{Standard Deviation} \\
Let $X$ be a discrete random variable. The \textit{standard deviation} of $X$ is given by,

\begin{gather*}
    \sigma_{X} = \sqrt{Var[X]} = \sqrt{\sum_{x_{i}} x_{i}^{2} p(x_{i}) - \mu_{x}^{2}} = \sqrt{E[X^2] - (E[X])^2}.
\end{gather*}

\noindent \textbf{Standardized Random Variable} \\
\indent Let $X$ be a discrete random variable and let $Z = \frac{X - \mu}{\sigma}$. Then $Z$ is called the \textbf{standardization of $X$}. The random variable $Z$ always has mean equal to 0 and standard deviation equal to 1.
\\

\noindent \textbf{Z-score} \\
\indent Let $x$ be a value form a probability distribution with mean $\mu$ and standard deviation $\sigma$. Then the \textbf{z-score} for $x$ is defined to be:

\begin{gather*}
    z = \frac{x - \mu}{\sigma}
\end{gather*}

\noindent \textbf{Markov Inequality} \\
\indent Let $Y$ be a discrete random variable taking only non-negative values, with finite mean $\mu_{Y}$. Then $\forall a > 0$,

\begin{gather*}
    \text{Pr}[Y>a] \leq \frac{\mu_{Y}}{a}.
\end{gather*}

\noindent \textbf{Chebychev's Theorem}\\
Let $X$ be a discrete random variable with finite mean $\mu_{X}$ and standard deviation $\sigma_{X}$. Let $k$ be greater than 1. Then the probability that $X$ is more than $k$ standard deviations from the mean, $\mu_{X}$, is less than or equal to $1/k^2$. That is,

\begin{gather*}
    \text{Pr}(X < \mu_{X} - k\cdot \sigma_{X} \ \ \text{or} \ \ X > \mu_{X} + k\cdot \sigma_{X}) =  \text{Pr}(\lvert X - \mu \rvert > k \cdot \sigma_{X}) \leq \frac{1}{k^2}.
\end{gather*}
\noindent Equivalently,
\begin{gather*}
    \text{Pr}(\mu_{X} - k\sigma_{X} \leq X \leq \mu_{X} + k\sigma_{X}) = \text{Pr}(\lvert X - \mu \rvert \leq k \cdot \sigma_{X}) \geq 1 - \frac{1}{k^2}.
\end{gather*}

\noindent \textbf{Outliers} \\
\indent We define an outlier to be any data point with a $z$-score less than $z = -3$ or greater than $z = 3$, i.e. more than 3 standard deviations away from the mean.\\

\noindent \textbf{Coefficient of Variation} \\
\indent A random variable $X$ with mean $\mu$ and standard deviation $\sigma$ has a coefficient of variation

\begin{gather*}
    \frac{100 \cdot \sigma}{\mu}\%
\end{gather*}

\noindent \textbf{Join Distribution and Independence} \\
\indent Let $X$ and $Y$ be random variables arising from the same discrete probability experiment. The \textbf{joint distribution} of $X$ and $Y$ is given by,

\begin{gather*}
    p(x,y) = \text{Pr}[\{X = x\} \cap \{Y = y\}]
\end{gather*}

\noindent We say $X$ and $Y$ are \textbf{independent} if $\forall x,y$ the events $\{X=x\}$ and $\{Y=y\}$ are independent. That is,
\begin{gather*}
    p(x,y) = \text{Pr}[\{X = x\} \cap \{Y = y\}] = \text{Pr}[X=x]\cdot \text{Pr}[Y=y] = p_{X}(x) \cdot p_{Y}(y)
\end{gather*}

For independence, let $X$ and $Y$ be random variables arising from the same probability experiment. Then,

\begin{gather*}
    E[X + Y] = E[X] + E[Y]. \text{This extends to sums of any length}.
\end{gather*}

\noindent Further, if $X$ and $Y$ are independent, then

\begin{gather*}
    E[X\cdot Y] = E[X] \cdot E[Y], \\
    Var[X + Y] = Var[X] + Var[Y].
\end{gather*}

\noindent The last equation extends to finite sums of any length provided the summands are pairwise independent.

\subsection{Discrete Distributions}
\noindent \textbf{Finite Summation Formulas} \\
\begin{gather*}
    \sum_{i=1}^{n} i = \frac{n(n+1)}{2} \\
    \sum_{i=1}^{n} i^2 = \frac{n(n+1)(2n+1)}{6} \\
    \sum_{n=0}^{N} ax^{n} = \frac{a(1-x^{N+1})}{1-x}
\end{gather*}

\noindent \textbf{Discrete Uniform Distribution} \\
\indent A random variable $X$ is said to have a discrete uniform distribution if its probability function is
\begin{gather*}
    \text{Pr}(X = x) = p(x) = \frac{1}{n} \quad \text{for}\ x = 1,2,...,n
\end{gather*}

\indent The mean and variance are then
\begin{gather*}
    E[X] = \frac{n+1}{2} \\
    Var[X] = \frac{n^2 - 1}{12}
\end{gather*}

\noindent \textbf{Bernoulli Random Variable}\\
\indent A \textbf{Bernoulli trial} is an experiment that has two outcomes, 1 or 0. Thus Pr$[X=1] = p$ and Pr$[X = 0] = q = 1 - p$. The mean and variance are given by
\begin{gather*}
    E[X] = p\\
    Var[X] = pq = p(1-p)
\end{gather*}

\noindent \textbf{Binomial Distribution} \\
\indent Let $Y$ be the number of successes in $n$ independent repetitions of a Bernoulli trial with probability of success $p$. The random variable $Y$ has the probability function given by
\begin{gather*}
    \text{Pr}(Y=y) = p(y) = {n \choose y}p^{y}q^{n-y} \quad \text{for}\ y=0,1,2,...,n\ \text{and}\ 0 \leq p \leq 1.
\end{gather*}

\noindent The mean and variance are with probability of success $p$ and $n$ trails is then
\begin{gather*}
    \mu_{Y} = E[Y] = np,\\
    \sigma_{Y}^{2} = Var[Y] = npq = np(1-p)
\end{gather*}

\noindent \textbf{Geometric Distribution} \\
\indent Consider a series of independent Bernoulli trials with probability of success $p$ and let the random variable $X$ be the number of failures before the first success. The random variable $X$ has the probability function given by
\begin{gather*}
    \text{Pr}[X=k] = pq^k
\end{gather*}

\noindent The mean and variance are given by
\begin{gather*}
    E[X] = \frac{q}{p}, \\
    Var[X] = \frac{p}{q^2}.
\end{gather*}

\noindent \textbf{Negative Binomial Distribution} \\
\indent The negative binomial distribution is a generalization of the geometric distribution. The requirements for a negative binomial process are:
\begin{itemize}
    \item[(i)] The trials are identical.
    \item[(ii)] Each trial is independent of the other trials.
    \item[(iii)] The random variable $M$ denotes the numver of failures prior to the $r^{th}$ success.
    \item[(iv)]  The probability of success is $p$ and the probability of failure is $q$.
\end{itemize}

\indent The probability distribution is then
\begin{gather*}
    \text{Pr}(M=k) = {r+k-1 \choose k} p^{r}q^{k}.
\end{gather*}

\noindent The mean and variance of this distribution is then,
\begin{gather*}
    E[M] = \frac{rq}{p},\\
    Var[M] = \frac{rq}{p^{2}}.
\end{gather*}

\noindent \textbf{Hyper-Geometric Distribution} \\
\indent A finite population consists of $B$ objects of type 1 and $G$ objects of type 2. Let $X$ be the number of type 1 objects in a sample of size $n$ selected without replacement. Then,
\begin{gather*}
    \text{Pr}(X = k) = \frac{_{B}C_{k} \cdot _{G}C_{n-k}}{_{B+G}C_{n}}
\end{gather*}

\noindent with $0 \leq k \leq B$ and $0 \leq n - k \leq G$. Then $X$ (the number of successes) is called a hyper-geometric random variable. The mean and variance of this distribution is then
\begin{gather*}
    E[X] = n\left ( \frac{B}{B+G}\right ),\\
    Var[X] = n\left ( \frac{B}{B+G}\right ) \left ( \frac{G}{B+G}\right ) \left ( \frac{B+G-n}{B+G-1}\right ).
\end{gather*}

\subsection{Moments}
The $n$th moment of $X$ for a discrete variable is defined as:

\begin{gather*}
    \braket{x^n} = \sum_{i=1}^{j}x^{n}P(x_{i})
\end{gather*}

\noindent where the first moment is just the average over the sample space, and the second moment is the variance of $X$. More generally, we can write

\begin{gather*}
    \braket{f(x)} = \sum_{i=0}^{\infty} f(x) P(x_{i})
\end{gather*}

\indent For a continous variable, the sums turn into integrals to cover the entire sample space. The $n$th moment of $X$ is then defined as

\begin{gather*}
    \braket{x^n} = \int_{-\infty}^{\infty} x^n P(x) dx
\end{gather*}

\noindent and more generally we can write

\begin{gather*}
    \braket{f(x)} = \int_{-\infty}^{\infty} f(x) P(x) dx
\end{gather*}

\indent The standard deviation is then equal to

\begin{gather*}
    \sigma = \sqrt{\braket{(\Delta x)^{2}}} = \sqrt{\braket{x^2} - \braket{x}^2}. 
\end{gather*}

\subsection{Standard deviation}

The standard deviation can be calculated as follows.
\begin{gather*}
    (\Delta j)^2 = (j - \braket{j})^2 \\
    \braket{(\Delta j)^{2}} = \sum (\Delta j)^2 P(j) = \sum (j-\braket{j})^2 P(j) \\
    = \sum (j^2 - 2j\braket{j} + \braket{j}^2) P(j) = \sum j^2 P(j) - 2\braket{j}\sum j P(j) + \braket{j}^2 \sum P(j) \\
    = \braket{j^2} - 2\braket{j}^2 + \braket{j}^2 = \braket{j^2} - \braket{j}^2 = \sigma^{2}
\end{gather*}

\end{document}
